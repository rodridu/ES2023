{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80892f31-3ad5-4369-bb34-c436be8f1fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.linear_model import LinearRegression, LassoCV\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed7ebb08-000e-4201-8b5d-9927c9b61dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/hongz/Downloads/choices13k-main/reg_data_main2.csv\")\n",
    "# Modify graph_id as specified\n",
    "data['graph_id'] = data['graph_id'] + 100 * data['reshuffle_ind']\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60251ca6-b71a-4b1e-8433-7805958d6d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>graph_id</th>\n",
       "      <th>time</th>\n",
       "      <th>click</th>\n",
       "      <th>risk</th>\n",
       "      <th>forecast</th>\n",
       "      <th>confidence</th>\n",
       "      <th>investment</th>\n",
       "      <th>reason_risky</th>\n",
       "      <th>reason_confidence</th>\n",
       "      <th>...</th>\n",
       "      <th>employment_ind</th>\n",
       "      <th>education_ind</th>\n",
       "      <th>income_ind</th>\n",
       "      <th>statistics_ind</th>\n",
       "      <th>risk-taking_ind</th>\n",
       "      <th>stock knowledge_ind</th>\n",
       "      <th>frequency _ind</th>\n",
       "      <th>history_ind</th>\n",
       "      <th>technical_ind</th>\n",
       "      <th>subject_id_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5fbb4426e47b46c3e2eeb544</td>\n",
       "      <td>156</td>\n",
       "      <td>11.550</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>112</td>\n",
       "      <td>62</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65981b2c1df3be0020afa351</td>\n",
       "      <td>154</td>\n",
       "      <td>57.601</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>95</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>The ones that had big dips in them.</td>\n",
       "      <td>A lot of them. Only because I'm slowly trying ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655791684bb1c5db02826d17</td>\n",
       "      <td>192</td>\n",
       "      <td>48.958</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>91</td>\n",
       "      <td>100</td>\n",
       "      <td>51</td>\n",
       "      <td>If it fluctuates more than 20% within 12 months.</td>\n",
       "      <td>With a $3 investment I do not feel unconfident...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62ddbd7eb3e9431e49b46ec1</td>\n",
       "      <td>182</td>\n",
       "      <td>49.950</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>115</td>\n",
       "      <td>79</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5fb13091b87dfd5888f73e05</td>\n",
       "      <td>180</td>\n",
       "      <td>45.070</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>93</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>Those that have big drops.</td>\n",
       "      <td>When they are inconsistent and up and down on ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 subject_id  graph_id    time  click  risk  forecast  \\\n",
       "0  5fbb4426e47b46c3e2eeb544       156  11.550      6     6       112   \n",
       "1  65981b2c1df3be0020afa351       154  57.601     10     8        95   \n",
       "2  655791684bb1c5db02826d17       192  48.958     16     7        91   \n",
       "3  62ddbd7eb3e9431e49b46ec1       182  49.950     11     8       115   \n",
       "4  5fb13091b87dfd5888f73e05       180  45.070      8     5        93   \n",
       "\n",
       "   confidence  investment                                      reason_risky  \\\n",
       "0          62          59                                               NaN   \n",
       "1          14           9               The ones that had big dips in them.   \n",
       "2         100          51  If it fluctuates more than 20% within 12 months.   \n",
       "3          79          60                                               NaN   \n",
       "4          20           0                        Those that have big drops.   \n",
       "\n",
       "                                   reason_confidence  ...  employment_ind  \\\n",
       "0                                                NaN  ...               0   \n",
       "1  A lot of them. Only because I'm slowly trying ...  ...               1   \n",
       "2  With a $3 investment I do not feel unconfident...  ...               1   \n",
       "3                                                NaN  ...               1   \n",
       "4  When they are inconsistent and up and down on ...  ...               0   \n",
       "\n",
       "   education_ind  income_ind  statistics_ind  risk-taking_ind  \\\n",
       "0              1           1               0                0   \n",
       "1              0           0               1                1   \n",
       "2              1           1               0                1   \n",
       "3              1           0               1                1   \n",
       "4              0           0               0                1   \n",
       "\n",
       "   stock knowledge_ind  frequency _ind  history_ind  technical_ind  \\\n",
       "0                    0               0            0              0   \n",
       "1                    0               1            0              0   \n",
       "2                    0               1            1              0   \n",
       "3                    0               0            0              0   \n",
       "4                    0               1            1              0   \n",
       "\n",
       "   subject_id_encoded  \n",
       "0                 185  \n",
       "1                 461  \n",
       "2                 438  \n",
       "3                 307  \n",
       "4                 183  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform 'subject_id' to numeric\n",
    "data['subject_id_encoded'] = le.fit_transform(data['subject_id'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f3373d1-f85c-42c5-abbb-152e843d8d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0024500085804841643"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define independent variables for the baseline regression\n",
    "X_base = data[['Obj_Std', 'Skewness', 'Kurtosis', 'time', 'click', 'order']]\n",
    "\n",
    "# Split the data\n",
    "X_train_base, X_test_base, y_train, y_test = train_test_split(X_base, data['confidence'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Baseline regression\n",
    "model_base = LinearRegression()\n",
    "model_base.fit(X_train_base, y_train)\n",
    "y_pred_base = model_base.predict(X_test_base)\n",
    "r2_base = r2_score(y_test, y_pred_base)\n",
    "r2_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9da26e22-49ec-41d3-84eb-3df309687e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003029619230456193"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_3_feature = data[['Obj_Std', 'Skewness', 'Kurtosis', 'time', 'click', 'order', 'Recency_Factor', 'Rep_Factor', 'Sign_Factor']]\n",
    "X_train_3, X_test_3 = train_test_split(X_3_feature, test_size=0.2, random_state=42)\n",
    "\n",
    "model_3_feature = LinearRegression()\n",
    "model_3_feature.fit(X_train_3, y_train)\n",
    "y_pred_3 = model_3_feature.predict(X_test_3)\n",
    "r2_3_feature = r2_score(y_test, y_pred_3)\n",
    "r2_3_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "666ba2c7-8663-4a36-9b36-40cb1dbe86fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005858440493053729"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_8_feature = data[['Obj_Std', 'Skewness', 'Kurtosis', 'time', 'click', 'order', 'subject_id_encoded', 'Recency_Factor', 'Rep_Factor', 'Sign_Factor', 'SH_Rep_Factor', 'SH_Sign_Factor', 'SH_Obj_Std', 'SH_Skewness', 'SH_Kurtosis']]\n",
    "X_train_8, X_test_8 = train_test_split(X_8_feature, test_size=0.2, random_state=42)\n",
    "\n",
    "model_8_feature = LinearRegression()\n",
    "model_8_feature.fit(X_train_8, y_train)\n",
    "y_pred_8 = model_8_feature.predict(X_test_8)\n",
    "r2_8_feature = r2_score(y_test, y_pred_8)\n",
    "r2_8_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5a4a310-a63a-49a9-84cf-b65f15c6fcfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.008608796030070032"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_id_dummies = pd.get_dummies(data['graph_id'], prefix='graph_id')\n",
    "data_with_fe = pd.concat([data, graph_id_dummies], axis=1)\n",
    "\n",
    "# Assuming 'data' is your DataFrame and 'graph_id' is the categorical variable\n",
    "graph_id_dummies = pd.get_dummies(data['graph_id'], prefix='graph_id')\n",
    "data_with_fe = pd.concat([data, graph_id_dummies], axis=1)\n",
    "\n",
    "# Create a list of features including the dummy variables\n",
    "features = ['time', 'click', 'order'] + list(graph_id_dummies.columns)\n",
    "\n",
    "# Select these features for X\n",
    "X_graph_id_fe = data_with_fe[features]\n",
    "\n",
    "# Assuming y_train and y_test are defined or create them if not mentioned\n",
    "X_train_graph_id_fe, X_test_graph_id_fe = train_test_split(X_graph_id_fe, test_size=0.2, random_state=42)\n",
    "#X_train_graph_id_fe, X_test_graph_id_fe, y_train, y_test = train_test_split(X_graph_id_fe, data['confidence'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the baseline regression model\n",
    "model_graph_id_fe = LinearRegression()\n",
    "model_graph_id_fe.fit(X_train_graph_id_fe, y_train)\n",
    "\n",
    "# Predict and calculate the R-squared value\n",
    "y_pred_graph_id_fe = model_graph_id_fe.predict(X_test_graph_id_fe)\n",
    "r2_graph_id_fe = r2_score(y_test, y_pred_graph_id_fe)\n",
    "\n",
    "r2_graph_id_fe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbc6d87-1cbf-4966-8b6d-2396afc834ae",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c4c3437-55cc-4a05-b81a-b8ae64ce58ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify all 'ret_' and 'price_' columns\n",
    "ret_columns = [col for col in data.columns if col.startswith('ret_')]\n",
    "price_columns = [col for col in data.columns if col.startswith('price_')]\n",
    "\n",
    "# Identify all 'ret_', 'price_', and their differences columns\n",
    "ret_1st_diff_columns = [col for col in data.columns if '1st_diff' in col and col.startswith('ret_')]\n",
    "ret_2nd_diff_columns = [col for col in data.columns if '2nd_diff' in col and col.startswith('ret_')]\n",
    "price_1st_diff_columns = [col for col in data.columns if '1st_diff' in col and col.startswith('price_')]\n",
    "price_2nd_diff_columns = [col for col in data.columns if '2nd_diff' in col and col.startswith('price_')]\n",
    "\n",
    "# Combine these columns with your other features for the Huge Lasso model\n",
    "features_huge_lasso = ['Obj_Std', 'Skewness', 'Kurtosis', 'time', 'click', 'order', 'subject_id_encoded', 'Recency_Factor', 'Rep_Factor', 'Sign_Factor', 'SH_Rep_Factor', 'SH_Sign_Factor', 'SH_Obj_Std', 'SH_Skewness', 'SH_Kurtosis'] + ret_columns + price_columns + ret_1st_diff_columns + ret_2nd_diff_columns + price_1st_diff_columns + price_2nd_diff_columns\n",
    "X_huge_lasso = data[features_huge_lasso]\n",
    "X_train_huge, X_test_huge = train_test_split(X_huge_lasso, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa2bc2da-731f-4608-80fc-6b9cbf86b17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean R-squared for Lasso with 10-Fold CV: 0.0030 ± 0.0038\n"
     ]
    }
   ],
   "source": [
    "def lasso_kfold_cv(data, features, target):\n",
    "    X = data[features]\n",
    "    y = data[target]\n",
    "    \n",
    "    # Standardizing the data\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Setting up 10-fold cross-validation\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Using LassoCV to find the best alpha during cross-validation\n",
    "    lasso_cv = LassoCV(alphas=np.logspace(-6, 0, 100), cv=kf, random_state=42)\n",
    "    lasso_cv.fit(X_scaled, y)\n",
    "\n",
    "    # Evaluating the model using cross-validation\n",
    "    cv_scores = cross_val_score(lasso_cv, X_scaled, y, cv=kf, scoring='r2')\n",
    "    mean_r2 = np.mean(cv_scores)\n",
    "    std_r2 = np.std(cv_scores)\n",
    "\n",
    "    return mean_r2, std_r2\n",
    "\n",
    "# Using the model\n",
    "features_base = ['Obj_Std', 'Skewness', 'Kurtosis', 'time', 'click', 'order',  'Recency_Factor', 'Rep_Factor', 'Sign_Factor', 'SH_Rep_Factor', 'SH_Sign_Factor', 'SH_Obj_Std', 'SH_Skewness', 'SH_Kurtosis']\n",
    "r2_8_feature_lasso, std_8_feature_lasso = lasso_kfold_cv(data, features_base, 'confidence')\n",
    "print(f\"Mean R-squared for Lasso with 10-Fold CV: {r2_8_feature_lasso:.4f} ± {std_8_feature_lasso:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b115eeae-a070-4d53-9a47-1c4985dcdb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean R-squared for Large Lasso with 10-Fold CV: 0.0027 ± 0.0034\n",
      "Mean R-squared for Huge Lasso with 10-Fold CV: 0.0026 ± 0.0033\n"
     ]
    }
   ],
   "source": [
    "# Extracting ret and price features\n",
    "ret_features = [col for col in data.columns if col.startswith('ret_') and 'diff' not in col]\n",
    "price_features = [col for col in data.columns if col.startswith('price_') and 'diff' not in col]\n",
    "\n",
    "# Large Lasso features include base features plus all ret_ and price_ values\n",
    "features_large = features_base + ret_features + price_features\n",
    "\n",
    "# Adding first and second differences for Huge Lasso features\n",
    "ret_diff_features = [col for col in data.columns if 'ret_' in col and 'diff' in col]\n",
    "price_diff_features = [col for col in data.columns if 'price_' in col and 'diff' in col]\n",
    "\n",
    "features_huge = features_large + ret_diff_features + price_diff_features\n",
    "\n",
    "# Calculate R-squared for Large Lasso\n",
    "r2_large_lasso, std_r2_large = lasso_kfold_cv(data, features_large, 'confidence')\n",
    "print(f\"Mean R-squared for Large Lasso with 10-Fold CV: {r2_large_lasso:.4f} ± {std_r2_large:.4f}\")\n",
    "\n",
    "# Calculate R-squared for Huge Lasso\n",
    "r2_huge_lasso, std_r2_huge = lasso_kfold_cv(data, features_huge, 'confidence')\n",
    "print(f\"Mean R-squared for Huge Lasso with 10-Fold CV: {r2_huge_lasso:.4f} ± {std_r2_huge:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d4b7d1-11b1-4995-a518-76afd4981ae6",
   "metadata": {},
   "source": [
    "lasso within subjected_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44a78a6f-1874-43bd-b6a7-2951120d14dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean R-squared for Lasso with 10-Fold CV: -0.0173 ± 0.0165\n"
     ]
    }
   ],
   "source": [
    "from sklearn import set_config\n",
    "set_config(enable_metadata_routing=False)  # Explicitly disable metadata routing\n",
    "\n",
    "def lasso_group_kfold_cv(data, features, target):\n",
    "    X = data[features]\n",
    "    y = data[target]\n",
    "    groups = data['subject_id_encoded']  # This assumes subject_id_encoded is a column in the DataFrame\n",
    "\n",
    "    # Setting up 10-fold cross-validation that respects groups\n",
    "    gkf = GroupKFold(n_splits=10)\n",
    "\n",
    "    # Create a pipeline to scale data and apply Lasso\n",
    "    lasso_pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('lasso_cv', LassoCV(alphas=np.logspace(-6, 0, 100), max_iter=10000, random_state=42))\n",
    "    ])\n",
    "\n",
    "    # Compute cross-validated R^2 scores\n",
    "    cv_scores = cross_val_score(lasso_pipeline, X, y, groups=groups, cv=gkf, scoring='r2')\n",
    "    mean_r2 = np.mean(cv_scores)\n",
    "    std_r2 = np.std(cv_scores)\n",
    "\n",
    "    return mean_r2, std_r2\n",
    "\n",
    "# Usage example\n",
    "features_base = ['Obj_Std', 'Skewness', 'Kurtosis', 'time', 'click', 'order', 'subject_id_encoded', 'Recency_Factor', 'Rep_Factor', 'Sign_Factor', 'SH_Rep_Factor', 'SH_Sign_Factor', 'SH_Obj_Std', 'SH_Skewness', 'SH_Kurtosis']\n",
    "r2_8_feature_lasso, std_8_feature_lasso = lasso_group_kfold_cv(data, features_base, 'confidence')\n",
    "print(f\"Mean R-squared for Lasso with 10-Fold CV: {r2_8_feature_lasso:.4f} ± {std_8_feature_lasso:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c760b4d4-3bf8-416e-900b-632c289f2e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean R-squared for Large Lasso with 10-Fold CV: -0.0143 ± 0.0158\n",
      "Mean R-squared for Huge Lasso with 10-Fold CV: -0.0144 ± 0.0158\n"
     ]
    }
   ],
   "source": [
    "# Large Lasso\n",
    "r2_large_lasso, std_r2_large_lasso = lasso_group_kfold_cv(data, features_large, 'confidence')\n",
    "print(f\"Mean R-squared for Large Lasso with 10-Fold CV: {r2_large_lasso:.4f} ± {std_r2_large_lasso:.4f}\")\n",
    "\n",
    "# Huge Lasso\n",
    "r2_huge_lasso, std_r2_huge_lasso = lasso_group_kfold_cv(data, features_huge, 'confidence')\n",
    "print(f\"Mean R-squared for Huge Lasso with 10-Fold CV: {r2_huge_lasso:.4f} ± {std_r2_huge_lasso:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecdee433-2f04-424d-bb37-42dda385692f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model(Confidence No Subject)</th>\n",
       "      <th>R-squared (Without Subject ID FE)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline Regression</td>\n",
       "      <td>0.002450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3-feature Regression</td>\n",
       "      <td>0.003030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8-feature Regression</td>\n",
       "      <td>0.005858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8-feature Lasso</td>\n",
       "      <td>-0.017289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Large Lasso</td>\n",
       "      <td>-0.014291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Huge Lasso</td>\n",
       "      <td>-0.014291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Graph FE Regression</td>\n",
       "      <td>-0.008609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model(Confidence No Subject)  R-squared (Without Subject ID FE)\n",
       "0          Baseline Regression                           0.002450\n",
       "1         3-feature Regression                           0.003030\n",
       "2         8-feature Regression                           0.005858\n",
       "3              8-feature Lasso                          -0.017289\n",
       "4                  Large Lasso                          -0.014291\n",
       "5                   Huge Lasso                          -0.014291\n",
       "6          Graph FE Regression                          -0.008609"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the DataFrame\n",
    "dak = {\n",
    "    \"Model(Confidence No Subject)\": [\n",
    "        \"Baseline Regression\", \"3-feature Regression\", \"8-feature Regression\",\n",
    "        \"8-feature Lasso\", \"Large Lasso\", \"Huge Lasso\", \"Graph FE Regression\"\n",
    "    ],\n",
    "    \"R-squared (Without Subject ID FE)\": [\n",
    "        r2_base, r2_3_feature, r2_8_feature,\n",
    "        r2_8_feature_lasso, r2_large_lasso, r2_large_lasso, r2_graph_id_fe\n",
    "    ],\n",
    "    # \"R-squared (With Subject ID FE)\": [\n",
    "    #     r2_baseline_fe, r2_3_feature_fe, r2_8_feature_fe,\n",
    "    #     r2_8_feature_lasso_fe, r2_large_lasso_fe, r2_large_lasso_fe, r2_graph_fe\n",
    "    # ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(dak)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f822b64-7a73-4a46-a2ec-c15ec66f329f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0ea3e1-43a0-40c5-b974-ec0587b5f938",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
