{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da7c91c4-043d-47dd-a36f-a9c285cf0c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.linear_model import LinearRegression, LassoCV\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Applying a more readable float format\n",
    "pd.options.display.float_format = '{:.8f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6934f4fe-49e7-4fd3-bac7-496e95e101b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>graph_id</th>\n",
       "      <th>time</th>\n",
       "      <th>click</th>\n",
       "      <th>risk</th>\n",
       "      <th>forecast</th>\n",
       "      <th>confidence</th>\n",
       "      <th>investment</th>\n",
       "      <th>reason_risky</th>\n",
       "      <th>reason_confidence</th>\n",
       "      <th>...</th>\n",
       "      <th>gender_ind</th>\n",
       "      <th>employment_ind</th>\n",
       "      <th>education_ind</th>\n",
       "      <th>income_ind</th>\n",
       "      <th>statistics_ind</th>\n",
       "      <th>risk-taking_ind</th>\n",
       "      <th>stock knowledge_ind</th>\n",
       "      <th>frequency _ind</th>\n",
       "      <th>history_ind</th>\n",
       "      <th>technical_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5fbb4426e47b46c3e2eeb544</td>\n",
       "      <td>156</td>\n",
       "      <td>11.55000000</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>112</td>\n",
       "      <td>62</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65981b2c1df3be0020afa351</td>\n",
       "      <td>154</td>\n",
       "      <td>57.60100000</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>95</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>The ones that had big dips in them.</td>\n",
       "      <td>A lot of them. Only because I'm slowly trying ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655791684bb1c5db02826d17</td>\n",
       "      <td>192</td>\n",
       "      <td>48.95800000</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>91</td>\n",
       "      <td>100</td>\n",
       "      <td>51</td>\n",
       "      <td>If it fluctuates more than 20% within 12 months.</td>\n",
       "      <td>With a $3 investment I do not feel unconfident...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62ddbd7eb3e9431e49b46ec1</td>\n",
       "      <td>182</td>\n",
       "      <td>49.95000000</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>115</td>\n",
       "      <td>79</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5fb13091b87dfd5888f73e05</td>\n",
       "      <td>180</td>\n",
       "      <td>45.07000000</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>93</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>Those that have big drops.</td>\n",
       "      <td>When they are inconsistent and up and down on ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10035</th>\n",
       "      <td>65a038f02fb72900ba2653fc</td>\n",
       "      <td>67</td>\n",
       "      <td>26.48100000</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>106</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>Any stocks with dramatic movements of price ei...</td>\n",
       "      <td>Those kinds of risky prices where it goes up a...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10036</th>\n",
       "      <td>5596ab22fdf99b2d3a68c840</td>\n",
       "      <td>13</td>\n",
       "      <td>47.07800000</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>101</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>I think ones that have wide changes up and dow...</td>\n",
       "      <td>The ones that fluctuate randomly and have vari...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10037</th>\n",
       "      <td>65675f2ae0bb2e4ecb9c539d</td>\n",
       "      <td>31</td>\n",
       "      <td>20.73800000</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>105</td>\n",
       "      <td>87</td>\n",
       "      <td>13</td>\n",
       "      <td>High-volatility stocks are seen to be riskier ...</td>\n",
       "      <td>Stock price drops that are abrupt and sharp wi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10038</th>\n",
       "      <td>6296290ec41bde1525dbb77e</td>\n",
       "      <td>61</td>\n",
       "      <td>33.98900000</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>106</td>\n",
       "      <td>40</td>\n",
       "      <td>60</td>\n",
       "      <td>The ones going down and the ones that seem the...</td>\n",
       "      <td>The volatility in swings makes me unsure and n...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10039</th>\n",
       "      <td>5f084a7987a3fe028ff65b8a</td>\n",
       "      <td>3</td>\n",
       "      <td>21.91200000</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>65</td>\n",
       "      <td>42</td>\n",
       "      <td>the stocks whice changes downwards are more risky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10040 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     subject_id  graph_id        time  click  risk  forecast  \\\n",
       "0      5fbb4426e47b46c3e2eeb544       156 11.55000000      6     6       112   \n",
       "1      65981b2c1df3be0020afa351       154 57.60100000     10     8        95   \n",
       "2      655791684bb1c5db02826d17       192 48.95800000     16     7        91   \n",
       "3      62ddbd7eb3e9431e49b46ec1       182 49.95000000     11     8       115   \n",
       "4      5fb13091b87dfd5888f73e05       180 45.07000000      8     5        93   \n",
       "...                         ...       ...         ...    ...   ...       ...   \n",
       "10035  65a038f02fb72900ba2653fc        67 26.48100000     17     8       106   \n",
       "10036  5596ab22fdf99b2d3a68c840        13 47.07800000      6     8       101   \n",
       "10037  65675f2ae0bb2e4ecb9c539d        31 20.73800000     22     3       105   \n",
       "10038  6296290ec41bde1525dbb77e        61 33.98900000      9     6       106   \n",
       "10039  5f084a7987a3fe028ff65b8a         3 21.91200000     10     6        99   \n",
       "\n",
       "       confidence  investment  \\\n",
       "0              62          59   \n",
       "1              14           9   \n",
       "2             100          51   \n",
       "3              79          60   \n",
       "4              20           0   \n",
       "...           ...         ...   \n",
       "10035          47           0   \n",
       "10036          92           0   \n",
       "10037          87          13   \n",
       "10038          40          60   \n",
       "10039          65          42   \n",
       "\n",
       "                                            reason_risky  \\\n",
       "0                                                    NaN   \n",
       "1                    The ones that had big dips in them.   \n",
       "2       If it fluctuates more than 20% within 12 months.   \n",
       "3                                                    NaN   \n",
       "4                             Those that have big drops.   \n",
       "...                                                  ...   \n",
       "10035  Any stocks with dramatic movements of price ei...   \n",
       "10036  I think ones that have wide changes up and dow...   \n",
       "10037  High-volatility stocks are seen to be riskier ...   \n",
       "10038  The ones going down and the ones that seem the...   \n",
       "10039  the stocks whice changes downwards are more risky   \n",
       "\n",
       "                                       reason_confidence  ...  gender_ind  \\\n",
       "0                                                    NaN  ...           0   \n",
       "1      A lot of them. Only because I'm slowly trying ...  ...           0   \n",
       "2      With a $3 investment I do not feel unconfident...  ...           0   \n",
       "3                                                    NaN  ...           1   \n",
       "4      When they are inconsistent and up and down on ...  ...           0   \n",
       "...                                                  ...  ...         ...   \n",
       "10035  Those kinds of risky prices where it goes up a...  ...           0   \n",
       "10036  The ones that fluctuate randomly and have vari...  ...           0   \n",
       "10037  Stock price drops that are abrupt and sharp wi...  ...           0   \n",
       "10038  The volatility in swings makes me unsure and n...  ...           1   \n",
       "10039                                                NaN  ...           0   \n",
       "\n",
       "       employment_ind  education_ind  income_ind  statistics_ind  \\\n",
       "0                   0              1           1               0   \n",
       "1                   1              0           0               1   \n",
       "2                   1              1           1               0   \n",
       "3                   1              1           0               1   \n",
       "4                   0              0           0               0   \n",
       "...               ...            ...         ...             ...   \n",
       "10035               1              1           0               0   \n",
       "10036               1              1           0               1   \n",
       "10037               1              1           1               1   \n",
       "10038               0              0           0               1   \n",
       "10039               1              1           1               1   \n",
       "\n",
       "       risk-taking_ind  stock knowledge_ind  frequency _ind  history_ind  \\\n",
       "0                    0                    0               0            0   \n",
       "1                    1                    0               1            0   \n",
       "2                    1                    0               1            1   \n",
       "3                    1                    0               0            0   \n",
       "4                    1                    0               1            1   \n",
       "...                ...                  ...             ...          ...   \n",
       "10035                0                    0               0            0   \n",
       "10036                0                    0               1            1   \n",
       "10037                1                    0               1            0   \n",
       "10038                1                    0               0            1   \n",
       "10039                1                    1               0            0   \n",
       "\n",
       "       technical_ind  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "...              ...  \n",
       "10035              0  \n",
       "10036              0  \n",
       "10037              0  \n",
       "10038              1  \n",
       "10039              0  \n",
       "\n",
       "[10040 rows x 106 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:/Users/hongz/Downloads/choices13k-main/reg_data_main2.csv\")\n",
    "# Modify graph_id as specified\n",
    "data['graph_id'] = data['graph_id'] + 100 * data['reshuffle_ind']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb3a4ff1-acfc-4511-a213-00d30c1fd29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reason_risky          260\n",
      "reason_confidence     300\n",
      "statistics             40\n",
      "stock knowledge      1800\n",
      "frequency            1800\n",
      "attention            1800\n",
      "history              1800\n",
      "technical            1800\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "na_counts = data.isna().sum()\n",
    "print(na_counts[na_counts > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3680c2a6-47e3-460f-adbf-97ce2272db78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>graph_id</th>\n",
       "      <th>time</th>\n",
       "      <th>click</th>\n",
       "      <th>risk</th>\n",
       "      <th>forecast</th>\n",
       "      <th>confidence</th>\n",
       "      <th>investment</th>\n",
       "      <th>reason_risky</th>\n",
       "      <th>reason_confidence</th>\n",
       "      <th>...</th>\n",
       "      <th>employment_ind</th>\n",
       "      <th>education_ind</th>\n",
       "      <th>income_ind</th>\n",
       "      <th>statistics_ind</th>\n",
       "      <th>risk-taking_ind</th>\n",
       "      <th>stock knowledge_ind</th>\n",
       "      <th>frequency _ind</th>\n",
       "      <th>history_ind</th>\n",
       "      <th>technical_ind</th>\n",
       "      <th>subject_id_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5fbb4426e47b46c3e2eeb544</td>\n",
       "      <td>156</td>\n",
       "      <td>11.55000000</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>112</td>\n",
       "      <td>62</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65981b2c1df3be0020afa351</td>\n",
       "      <td>154</td>\n",
       "      <td>57.60100000</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>95</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>The ones that had big dips in them.</td>\n",
       "      <td>A lot of them. Only because I'm slowly trying ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655791684bb1c5db02826d17</td>\n",
       "      <td>192</td>\n",
       "      <td>48.95800000</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>91</td>\n",
       "      <td>100</td>\n",
       "      <td>51</td>\n",
       "      <td>If it fluctuates more than 20% within 12 months.</td>\n",
       "      <td>With a $3 investment I do not feel unconfident...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62ddbd7eb3e9431e49b46ec1</td>\n",
       "      <td>182</td>\n",
       "      <td>49.95000000</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>115</td>\n",
       "      <td>79</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5fb13091b87dfd5888f73e05</td>\n",
       "      <td>180</td>\n",
       "      <td>45.07000000</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>93</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>Those that have big drops.</td>\n",
       "      <td>When they are inconsistent and up and down on ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 subject_id  graph_id        time  click  risk  forecast  \\\n",
       "0  5fbb4426e47b46c3e2eeb544       156 11.55000000      6     6       112   \n",
       "1  65981b2c1df3be0020afa351       154 57.60100000     10     8        95   \n",
       "2  655791684bb1c5db02826d17       192 48.95800000     16     7        91   \n",
       "3  62ddbd7eb3e9431e49b46ec1       182 49.95000000     11     8       115   \n",
       "4  5fb13091b87dfd5888f73e05       180 45.07000000      8     5        93   \n",
       "\n",
       "   confidence  investment                                      reason_risky  \\\n",
       "0          62          59                                               NaN   \n",
       "1          14           9               The ones that had big dips in them.   \n",
       "2         100          51  If it fluctuates more than 20% within 12 months.   \n",
       "3          79          60                                               NaN   \n",
       "4          20           0                        Those that have big drops.   \n",
       "\n",
       "                                   reason_confidence  ...  employment_ind  \\\n",
       "0                                                NaN  ...               0   \n",
       "1  A lot of them. Only because I'm slowly trying ...  ...               1   \n",
       "2  With a $3 investment I do not feel unconfident...  ...               1   \n",
       "3                                                NaN  ...               1   \n",
       "4  When they are inconsistent and up and down on ...  ...               0   \n",
       "\n",
       "   education_ind  income_ind  statistics_ind  risk-taking_ind  \\\n",
       "0              1           1               0                0   \n",
       "1              0           0               1                1   \n",
       "2              1           1               0                1   \n",
       "3              1           0               1                1   \n",
       "4              0           0               0                1   \n",
       "\n",
       "   stock knowledge_ind  frequency _ind  history_ind  technical_ind  \\\n",
       "0                    0               0            0              0   \n",
       "1                    0               1            0              0   \n",
       "2                    0               1            1              0   \n",
       "3                    0               0            0              0   \n",
       "4                    0               1            1              0   \n",
       "\n",
       "   subject_id_encoded  \n",
       "0                 185  \n",
       "1                 461  \n",
       "2                 438  \n",
       "3                 307  \n",
       "4                 183  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform 'subject_id' to numeric\n",
    "data['subject_id_encoded'] = le.fit_transform(data['subject_id'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55678b4e-8c5c-4e80-bc8a-b62f19a7f761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>graph_id</th>\n",
       "      <th>time</th>\n",
       "      <th>click</th>\n",
       "      <th>risk</th>\n",
       "      <th>forecast</th>\n",
       "      <th>confidence</th>\n",
       "      <th>investment</th>\n",
       "      <th>reason_risky</th>\n",
       "      <th>reason_confidence</th>\n",
       "      <th>...</th>\n",
       "      <th>graph_id_191</th>\n",
       "      <th>graph_id_192</th>\n",
       "      <th>graph_id_193</th>\n",
       "      <th>graph_id_194</th>\n",
       "      <th>graph_id_195</th>\n",
       "      <th>graph_id_196</th>\n",
       "      <th>graph_id_197</th>\n",
       "      <th>graph_id_198</th>\n",
       "      <th>graph_id_199</th>\n",
       "      <th>graph_id_200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5fbb4426e47b46c3e2eeb544</td>\n",
       "      <td>156</td>\n",
       "      <td>11.55000000</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>112</td>\n",
       "      <td>62</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65981b2c1df3be0020afa351</td>\n",
       "      <td>154</td>\n",
       "      <td>57.60100000</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>95</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>The ones that had big dips in them.</td>\n",
       "      <td>A lot of them. Only because I'm slowly trying ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655791684bb1c5db02826d17</td>\n",
       "      <td>192</td>\n",
       "      <td>48.95800000</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>91</td>\n",
       "      <td>100</td>\n",
       "      <td>51</td>\n",
       "      <td>If it fluctuates more than 20% within 12 months.</td>\n",
       "      <td>With a $3 investment I do not feel unconfident...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62ddbd7eb3e9431e49b46ec1</td>\n",
       "      <td>182</td>\n",
       "      <td>49.95000000</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>115</td>\n",
       "      <td>79</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5fb13091b87dfd5888f73e05</td>\n",
       "      <td>180</td>\n",
       "      <td>45.07000000</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>93</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>Those that have big drops.</td>\n",
       "      <td>When they are inconsistent and up and down on ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 307 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 subject_id  graph_id        time  click  risk  forecast  \\\n",
       "0  5fbb4426e47b46c3e2eeb544       156 11.55000000      6     6       112   \n",
       "1  65981b2c1df3be0020afa351       154 57.60100000     10     8        95   \n",
       "2  655791684bb1c5db02826d17       192 48.95800000     16     7        91   \n",
       "3  62ddbd7eb3e9431e49b46ec1       182 49.95000000     11     8       115   \n",
       "4  5fb13091b87dfd5888f73e05       180 45.07000000      8     5        93   \n",
       "\n",
       "   confidence  investment                                      reason_risky  \\\n",
       "0          62          59                                               NaN   \n",
       "1          14           9               The ones that had big dips in them.   \n",
       "2         100          51  If it fluctuates more than 20% within 12 months.   \n",
       "3          79          60                                               NaN   \n",
       "4          20           0                        Those that have big drops.   \n",
       "\n",
       "                                   reason_confidence  ...  graph_id_191  \\\n",
       "0                                                NaN  ...             0   \n",
       "1  A lot of them. Only because I'm slowly trying ...  ...             0   \n",
       "2  With a $3 investment I do not feel unconfident...  ...             0   \n",
       "3                                                NaN  ...             0   \n",
       "4  When they are inconsistent and up and down on ...  ...             0   \n",
       "\n",
       "   graph_id_192  graph_id_193  graph_id_194  graph_id_195  graph_id_196  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             1             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   graph_id_197  graph_id_198  graph_id_199  graph_id_200  \n",
       "0             0             0             0             0  \n",
       "1             0             0             0             0  \n",
       "2             0             0             0             0  \n",
       "3             0             0             0             0  \n",
       "4             0             0             0             0  \n",
       "\n",
       "[5 rows x 307 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming 'data' is your DataFrame and 'graph_id' is the categorical variable\n",
    "graph_id_dummies = pd.get_dummies(data['graph_id'], prefix='graph_id')\n",
    "data = pd.concat([data, graph_id_dummies], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89f35d2f-6b94-4253-87a3-305d9d968bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>graph_id</th>\n",
       "      <th>time</th>\n",
       "      <th>click</th>\n",
       "      <th>risk</th>\n",
       "      <th>forecast</th>\n",
       "      <th>confidence</th>\n",
       "      <th>investment</th>\n",
       "      <th>reason_risky</th>\n",
       "      <th>reason_confidence</th>\n",
       "      <th>...</th>\n",
       "      <th>subject_id_492</th>\n",
       "      <th>subject_id_493</th>\n",
       "      <th>subject_id_494</th>\n",
       "      <th>subject_id_495</th>\n",
       "      <th>subject_id_496</th>\n",
       "      <th>subject_id_497</th>\n",
       "      <th>subject_id_498</th>\n",
       "      <th>subject_id_499</th>\n",
       "      <th>subject_id_500</th>\n",
       "      <th>subject_id_501</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5fbb4426e47b46c3e2eeb544</td>\n",
       "      <td>156</td>\n",
       "      <td>11.55000000</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>112</td>\n",
       "      <td>62</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65981b2c1df3be0020afa351</td>\n",
       "      <td>154</td>\n",
       "      <td>57.60100000</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>95</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>The ones that had big dips in them.</td>\n",
       "      <td>A lot of them. Only because I'm slowly trying ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655791684bb1c5db02826d17</td>\n",
       "      <td>192</td>\n",
       "      <td>48.95800000</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>91</td>\n",
       "      <td>100</td>\n",
       "      <td>51</td>\n",
       "      <td>If it fluctuates more than 20% within 12 months.</td>\n",
       "      <td>With a $3 investment I do not feel unconfident...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62ddbd7eb3e9431e49b46ec1</td>\n",
       "      <td>182</td>\n",
       "      <td>49.95000000</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>115</td>\n",
       "      <td>79</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5fb13091b87dfd5888f73e05</td>\n",
       "      <td>180</td>\n",
       "      <td>45.07000000</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>93</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>Those that have big drops.</td>\n",
       "      <td>When they are inconsistent and up and down on ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 809 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 subject_id  graph_id        time  click  risk  forecast  \\\n",
       "0  5fbb4426e47b46c3e2eeb544       156 11.55000000      6     6       112   \n",
       "1  65981b2c1df3be0020afa351       154 57.60100000     10     8        95   \n",
       "2  655791684bb1c5db02826d17       192 48.95800000     16     7        91   \n",
       "3  62ddbd7eb3e9431e49b46ec1       182 49.95000000     11     8       115   \n",
       "4  5fb13091b87dfd5888f73e05       180 45.07000000      8     5        93   \n",
       "\n",
       "   confidence  investment                                      reason_risky  \\\n",
       "0          62          59                                               NaN   \n",
       "1          14           9               The ones that had big dips in them.   \n",
       "2         100          51  If it fluctuates more than 20% within 12 months.   \n",
       "3          79          60                                               NaN   \n",
       "4          20           0                        Those that have big drops.   \n",
       "\n",
       "                                   reason_confidence  ...  subject_id_492  \\\n",
       "0                                                NaN  ...               0   \n",
       "1  A lot of them. Only because I'm slowly trying ...  ...               0   \n",
       "2  With a $3 investment I do not feel unconfident...  ...               0   \n",
       "3                                                NaN  ...               0   \n",
       "4  When they are inconsistent and up and down on ...  ...               0   \n",
       "\n",
       "   subject_id_493  subject_id_494  subject_id_495  subject_id_496  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   subject_id_497  subject_id_498  subject_id_499  subject_id_500  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   subject_id_501  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 809 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_id_dummies = pd.get_dummies(data['subject_id_encoded'], prefix='subject_id')\n",
    "# Add these dummy variables to the data\n",
    "data = pd.concat([data, subject_id_dummies], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c752b8be-8bc4-4072-9ba1-c667bca5dfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify all 'ret_' and 'price_' columns\n",
    "ret_columns = [col for col in data.columns if col.startswith('ret_')]\n",
    "price_columns = [col for col in data.columns if col.startswith('price_')]\n",
    "\n",
    "# Identify all 'ret_', 'price_', and their differences columns\n",
    "ret_1st_diff_columns = [col for col in data.columns if '1st_diff' in col and col.startswith('ret_')]\n",
    "ret_2nd_diff_columns = [col for col in data.columns if '2nd_diff' in col and col.startswith('ret_')]\n",
    "price_1st_diff_columns = [col for col in data.columns if '1st_diff' in col and col.startswith('price_')]\n",
    "price_2nd_diff_columns = [col for col in data.columns if '2nd_diff' in col and col.startswith('price_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "392ce31c-03bf-469f-90cf-ac388eb8769d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ret_2',\n",
       " 'ret_3',\n",
       " 'ret_1st_diff_3',\n",
       " 'ret_4',\n",
       " 'ret_1st_diff_4',\n",
       " 'ret_5',\n",
       " 'ret_1st_diff_5',\n",
       " 'ret_6',\n",
       " 'ret_1st_diff_6',\n",
       " 'ret_7',\n",
       " 'ret_1st_diff_7',\n",
       " 'ret_8',\n",
       " 'ret_1st_diff_8',\n",
       " 'ret_9',\n",
       " 'ret_1st_diff_9',\n",
       " 'ret_10',\n",
       " 'ret_1st_diff_10',\n",
       " 'ret_11',\n",
       " 'ret_1st_diff_11',\n",
       " 'ret_12',\n",
       " 'ret_1st_diff_12',\n",
       " 'ret_13',\n",
       " 'ret_1st_diff_13']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0e740ac-c4cd-4981-a7f8-58575049ec47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding first and second differences for Huge Lasso features\n",
    "ret_diff_features = [col for col in data.columns if 'ret_' in col and 'diff' in col]\n",
    "price_diff_features = [col for col in data.columns if 'price_' in col and 'diff' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e99d89f-8c1b-4b56-8f94-b8c658088660",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = data.groupby('subject_id')\n",
    "data_demeaned = grouped.transform(lambda x: x - x.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cebd8b9-8ab3-4896-806d-9fbab7e59f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# Assuming 'data' is your DataFrame and 'confidence' is the target variable\n",
    "# 'subject_id_encoded' is a column in 'data' that you want to group by during the split\n",
    "\n",
    "# Define your feature matrix X and target variable y\n",
    "X = data_demeaned.drop('confidence', axis=1)\n",
    "y = data_demeaned['confidence']\n",
    "\n",
    "# Create a GroupShuffleSplit instance\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Get the index of the split, using 'subject_id_encoded' to create groups\n",
    "train_idx, test_idx = next(gss.split(X, y, groups=data['subject_id_encoded']))\n",
    "\n",
    "# Split the data into training and testing sets based on the indices\n",
    "X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc937cf7-418d-4ec0-91a1-4a7eec6eec9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics           40\n",
      "stock knowledge    1800\n",
      "frequency          1800\n",
      "attention          1800\n",
      "history            1800\n",
      "technical          1800\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "na_counts = data_demeaned.isna().sum()\n",
    "print(na_counts[na_counts > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5be21fd-bd3e-4e6e-a406-36e47f7d69a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ede6342b-7185-4b5a-abbf-772c9b5fac5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0025376568324233517"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_features = ['Obj_Std', 'Skewness', 'Kurtosis', 'time', 'click', 'order', 'subject_id_encoded']\n",
    "\n",
    "X_train_base = X_train[base_features]\n",
    "X_test_base = X_test[base_features]\n",
    "\n",
    "# Baseline regression\n",
    "model_base = LinearRegression()\n",
    "model_base.fit(X_train_base, y_train)\n",
    "y_pred_base = model_base.predict(X_test_base)\n",
    "r2_base = r2_score(y_test, y_pred_base)\n",
    "r2_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2d0867e-ff35-4757-aecd-dc25e380be6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01750639517504826"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_3_feature = ['Obj_Std', 'Skewness', 'Kurtosis', 'time', 'click', 'order', 'subject_id_encoded', 'Recency_Factor', 'Rep_Factor', 'Sign_Factor']\n",
    "\n",
    "X_train_3_feature = X_train[X_3_feature]\n",
    "X_test_3_feature = X_test[X_3_feature]\n",
    "\n",
    "model_3_feature = LinearRegression()\n",
    "model_3_feature.fit(X_train_3_feature, y_train)\n",
    "y_pred_3 = model_3_feature.predict(X_test_3_feature)\n",
    "r2_3_feature = r2_score(y_test, y_pred_3)\n",
    "r2_3_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6925f213-ea4f-4465-b38c-c6a02e0fee5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017211752040003803"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_8_feature = ['Obj_Std', 'Skewness', 'Kurtosis', 'time', 'click', 'order', 'subject_id_encoded', 'Recency_Factor', 'Rep_Factor', 'Sign_Factor', 'SH_Rep_Factor', 'SH_Sign_Factor', 'SH_Obj_Std', 'SH_Skewness', 'SH_Kurtosis']\n",
    "\n",
    "X_train_8_feature = X_train[X_8_feature]\n",
    "X_test_8_feature = X_test[X_8_feature]\n",
    "\n",
    "model_8_feature = LinearRegression()\n",
    "model_8_feature.fit(X_train_8_feature, y_train)\n",
    "y_pred_8 = model_8_feature.predict(X_test_8_feature)\n",
    "r2_8_feature = r2_score(y_test, y_pred_8)\n",
    "r2_8_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b77f978-7a46-431f-86ef-2d3304bd9b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.004793997012477513"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['time', 'click', 'order', 'subject_id_encoded'] + list(graph_id_dummies.columns)\n",
    "\n",
    "# Select these features for X\n",
    "X_graph_id_train = X_train[features]\n",
    "X_graph_id_test = X_test[features]\n",
    "\n",
    "# Fit the baseline regression model\n",
    "model_graph_id_fe = LinearRegression()\n",
    "model_graph_id_fe.fit(X_graph_id_train, y_train)\n",
    "\n",
    "# Predict and calculate the R-squared value\n",
    "y_pred_graph_id_fe = model_graph_id_fe.predict(X_graph_id_test)\n",
    "r2_graph_id_fe = r2_score(y_test, y_pred_graph_id_fe)\n",
    "\n",
    "r2_graph_id_fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7048bbba-9fe2-4e2a-b3fb-9a3c2594aba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d39e0d0d-ea2e-4e3b-ab39-6fb7464b56a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0025376568324233517"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_features_with_dummies = ['Obj_Std', 'Skewness', 'Kurtosis', 'time', 'click', 'order'] + list(subject_id_dummies.columns)\n",
    "\n",
    "# Define the independent and dependent variables\n",
    "X_baseline_with_dummies_train = X_train[baseline_features_with_dummies]\n",
    "X_baseline_with_dummies_test = X_test[baseline_features_with_dummies]\n",
    "\n",
    "# Fit the baseline regression model\n",
    "model_baseline_with_dummies = LinearRegression()\n",
    "model_baseline_with_dummies.fit(X_baseline_with_dummies_train, y_train)\n",
    "\n",
    "# Predict and calculate the R-squared value\n",
    "y_pred_baseline = model_baseline_with_dummies.predict(X_baseline_with_dummies_test)\n",
    "r2_baseline_fe = r2_score(y_test, y_pred_baseline)\n",
    "\n",
    "r2_baseline_fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b475c0c6-a742-4448-9732-b76d744f9415",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- subject_id_encoded\nFeature names seen at fit time, yet now missing:\n- subject_id_0\n- subject_id_1\n- subject_id_10\n- subject_id_100\n- subject_id_101\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m model_3_feature\u001b[38;5;241m.\u001b[39mfit(X_3_feature_train, y_train)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Predict and calculate R-squared\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m y_pred_3_feature \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_3_feature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_3_feature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m r2_3_feature_fe \u001b[38;5;241m=\u001b[39m r2_score(y_test, X_3_feature_test)\n\u001b[0;32m     15\u001b[0m r2_3_feature_fe\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:286\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    273\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;124;03m    Predict using the linear model.\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;124;03m        Returns predicted values.\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:269\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    267\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 269\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    545\u001b[0m ):\n\u001b[0;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \n\u001b[0;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 608\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    614\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m     )\n\u001b[1;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- subject_id_encoded\nFeature names seen at fit time, yet now missing:\n- subject_id_0\n- subject_id_1\n- subject_id_10\n- subject_id_100\n- subject_id_101\n- ...\n"
     ]
    }
   ],
   "source": [
    "# Define 3-feature model variables\n",
    "features_3_feature = baseline_features_with_dummies + ['Recency_Factor', 'Rep_Factor', 'Sign_Factor']\n",
    "\n",
    "# Split the data for 3-feature model\n",
    "X_3_feature_train = X_train[features_3_feature]\n",
    "X_3_feature_test = X_test[features_3_feature]\n",
    "\n",
    "# Fit the 3-feature model\n",
    "model_3_feature = LinearRegression()\n",
    "model_3_feature.fit(X_3_feature_train, y_train)\n",
    "\n",
    "# Predict and calculate R-squared\n",
    "y_pred_3_feature = model_3_feature.predict(X_test_3_feature)\n",
    "r2_3_feature_fe = r2_score(y_test, X_3_feature_test)\n",
    "r2_3_feature_fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "916f3237-ebb7-44f1-862d-8ae30aa2937c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01721175204000369"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define 8-feature model variables including 'subject_id_encoded' dummies\n",
    "features_8_feature = baseline_features_with_dummies + ['Recency_Factor', 'Rep_Factor', 'Sign_Factor', 'SH_Rep_Factor', 'SH_Sign_Factor', 'SH_Obj_Std', 'SH_Skewness', 'SH_Kurtosis']\n",
    "\n",
    "# Split the data for 3-feature model\n",
    "X_8_feature_train = X_train[features_8_feature]\n",
    "X_8_feature_test = X_test[features_8_feature]\n",
    "\n",
    "# Fit the 8-feature model\n",
    "model_8_feature = LinearRegression()\n",
    "model_8_feature.fit(X_8_feature_train, y_train)\n",
    "\n",
    "# Predict and calculate R-squared\n",
    "y_pred_8_feature = model_8_feature.predict(X_8_feature_test)\n",
    "r2_8_feature_fe = r2_score(y_test, y_pred_8_feature)\n",
    "r2_8_feature_fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ceda0b-0f19-4bc9-8166-c780dff99233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbab61aa-8a98-4f6b-820c-612abdb2fc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_large = base_features + ret_columns + price_columns\n",
    "X_large_train = X_train[features_large]\n",
    "X_large_test = X_test[features_large]\n",
    "\n",
    "features_huge = features_large + ret_diff_features + price_diff_features\n",
    "X_large_train = X_train[features_huge]\n",
    "X_large_test = X_test[features_huge]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfa0d2b-e4d8-4259-962b-d1b233f069f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7338ea16-e7b2-4fb7-8b7e-3f0e38e8e34f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194e8e2e-7e27-4f6b-a8ff-1341a47f5ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "345b05e9-6f66-4893-a18f-b3f5d4f7e166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Alpha: 0.003727593720314938\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "\n",
    "def find_optimal_alpha(X_train, y_train):\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    alphas = np.logspace(-6, 1, 50)  # Generate 50 logarithmically spaced alphas between 10^-6 and 10^1\n",
    "    avg_r_squared = []\n",
    "\n",
    "    for alpha in alphas:\n",
    "        r_squared = []\n",
    "        for train_index, val_index in kf.split(X_train):\n",
    "            X_train_kf, X_val_kf = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "            y_train_kf, y_val_kf = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "            model = Lasso(alpha=alpha)\n",
    "            model.fit(X_train_kf, y_train_kf)\n",
    "            y_pred_kf = model.predict(X_val_kf)\n",
    "            r_squared.append(r2_score(y_val_kf, y_pred_kf))\n",
    "\n",
    "        avg_r_squared.append(np.mean(r_squared))\n",
    "\n",
    "    # Select alpha that maximizes the average R-squared\n",
    "    optimal_alpha = alphas[np.argmax(avg_r_squared)]\n",
    "    return optimal_alpha\n",
    "\n",
    "optimal_alpha = find_optimal_alpha(X_train_8_feature, y_train)\n",
    "print(\"Optimal Alpha:\", optimal_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c7c495-fa24-4893-bd18-adc571dcb03e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a735ec31-6d3c-43dd-a8a6-64989cd8e026",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLasso does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Train Lasso on 90% of the data\u001b[39;00m\n\u001b[0;32m     19\u001b[0m lasso \u001b[38;5;241m=\u001b[39m Lasso(alpha\u001b[38;5;241m=\u001b[39malpha)\n\u001b[1;32m---> 20\u001b[0m \u001b[43mlasso\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_cv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_cv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Apply coefficients to 10% of the data\u001b[39;00m\n\u001b[0;32m     23\u001b[0m y_pred_val \u001b[38;5;241m=\u001b[39m lasso\u001b[38;5;241m.\u001b[39mpredict(X_val_cv)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1349\u001b[0m     )\n\u001b[0;32m   1350\u001b[0m ):\n\u001b[1;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:955\u001b[0m, in \u001b[0;36mElasticNet.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_input:\n\u001b[0;32m    954\u001b[0m     X_copied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept\n\u001b[1;32m--> 955\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mF\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_copied\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    965\u001b[0m     y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    966\u001b[0m         y, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    967\u001b[0m     )\n\u001b[0;32m    969\u001b[0m n_samples, n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1192\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1187\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1190\u001b[0m     )\n\u001b[1;32m-> 1192\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1206\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1208\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1210\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1003\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    997\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    998\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    999\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1000\u001b[0m     )\n\u001b[0;32m   1002\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m-> 1003\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1012\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:126\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 126\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:175\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    163\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    174\u001b[0m     )\n\u001b[1;32m--> 175\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nLasso does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# Initialize variables\n",
    "alphas = np.logspace(-6, 6, 13)\n",
    "best_alpha = None\n",
    "best_r2 = -np.inf\n",
    "\n",
    "# KFold split for cross-validation within the training set\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Loop through each alpha\n",
    "for alpha in alphas:\n",
    "    r2_scores = []\n",
    "    \n",
    "    # 10-fold cross-validation\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_train_cv, X_val_cv = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_train_cv, y_val_cv = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "        \n",
    "        # Train Lasso on 90% of the data\n",
    "        lasso = Lasso(alpha=alpha)\n",
    "        lasso.fit(X_train_cv, y_train_cv)\n",
    "        \n",
    "        # Apply coefficients to 10% of the data\n",
    "        y_pred_val = lasso.predict(X_val_cv)\n",
    "        \n",
    "        # Calculate R-squared for the validation set\n",
    "        r2 = r2_score(y_val_cv, y_pred_val)\n",
    "        r2_scores.append(r2)\n",
    "    \n",
    "    # Average the R-squared scores for this alpha\n",
    "    avg_r2 = np.mean(r2_scores)\n",
    "    \n",
    "    # Update best alpha if this one is better\n",
    "    if avg_r2 > best_r2:\n",
    "        best_r2 = avg_r2\n",
    "        best_alpha = alpha\n",
    "\n",
    "# Train final Lasso model on the entire training set using the best alpha\n",
    "lasso_final = Lasso(alpha=best_alpha)\n",
    "lasso_final.fit(X_train_8_feature, y_train)\n",
    "\n",
    "# Apply coefficients to the testing set\n",
    "y_pred_test = lasso_final.predict(X_test_8_feature)\n",
    "\n",
    "# Calculate R-squared for the testing set\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Best alpha:\", best_alpha)\n",
    "print(\"R-squared on the testing set:\", r2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d80c82-551e-4739-8eb1-58356dc90b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
