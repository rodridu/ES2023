{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2cbe5f03-350e-4661-844a-373896cabcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.linear_model import LinearRegression, LassoCV\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Applying a more readable float format\n",
    "pd.options.display.float_format = '{:.8f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "41c6989c-92b3-4720-9c6e-0bf0329473f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>graph_id</th>\n",
       "      <th>time</th>\n",
       "      <th>click</th>\n",
       "      <th>risk</th>\n",
       "      <th>forecast</th>\n",
       "      <th>confidence</th>\n",
       "      <th>investment</th>\n",
       "      <th>reason_risky</th>\n",
       "      <th>reason_confidence</th>\n",
       "      <th>...</th>\n",
       "      <th>gender_ind</th>\n",
       "      <th>employment_ind</th>\n",
       "      <th>education_ind</th>\n",
       "      <th>income_ind</th>\n",
       "      <th>statistics_ind</th>\n",
       "      <th>risk-taking_ind</th>\n",
       "      <th>stock knowledge_ind</th>\n",
       "      <th>frequency _ind</th>\n",
       "      <th>history_ind</th>\n",
       "      <th>technical_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5fbb4426e47b46c3e2eeb544</td>\n",
       "      <td>156</td>\n",
       "      <td>11.55000000</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>112</td>\n",
       "      <td>62</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65981b2c1df3be0020afa351</td>\n",
       "      <td>154</td>\n",
       "      <td>57.60100000</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>95</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>The ones that had big dips in them.</td>\n",
       "      <td>A lot of them. Only because I'm slowly trying ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655791684bb1c5db02826d17</td>\n",
       "      <td>192</td>\n",
       "      <td>48.95800000</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>91</td>\n",
       "      <td>100</td>\n",
       "      <td>51</td>\n",
       "      <td>If it fluctuates more than 20% within 12 months.</td>\n",
       "      <td>With a $3 investment I do not feel unconfident...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62ddbd7eb3e9431e49b46ec1</td>\n",
       "      <td>182</td>\n",
       "      <td>49.95000000</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>115</td>\n",
       "      <td>79</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5fb13091b87dfd5888f73e05</td>\n",
       "      <td>180</td>\n",
       "      <td>45.07000000</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>93</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>Those that have big drops.</td>\n",
       "      <td>When they are inconsistent and up and down on ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 subject_id  graph_id        time  click  risk  forecast  \\\n",
       "0  5fbb4426e47b46c3e2eeb544       156 11.55000000      6     6       112   \n",
       "1  65981b2c1df3be0020afa351       154 57.60100000     10     8        95   \n",
       "2  655791684bb1c5db02826d17       192 48.95800000     16     7        91   \n",
       "3  62ddbd7eb3e9431e49b46ec1       182 49.95000000     11     8       115   \n",
       "4  5fb13091b87dfd5888f73e05       180 45.07000000      8     5        93   \n",
       "\n",
       "   confidence  investment                                      reason_risky  \\\n",
       "0          62          59                                               NaN   \n",
       "1          14           9               The ones that had big dips in them.   \n",
       "2         100          51  If it fluctuates more than 20% within 12 months.   \n",
       "3          79          60                                               NaN   \n",
       "4          20           0                        Those that have big drops.   \n",
       "\n",
       "                                   reason_confidence  ...  gender_ind  \\\n",
       "0                                                NaN  ...           0   \n",
       "1  A lot of them. Only because I'm slowly trying ...  ...           0   \n",
       "2  With a $3 investment I do not feel unconfident...  ...           0   \n",
       "3                                                NaN  ...           1   \n",
       "4  When they are inconsistent and up and down on ...  ...           0   \n",
       "\n",
       "   employment_ind  education_ind  income_ind  statistics_ind  risk-taking_ind  \\\n",
       "0               0              1           1               0                0   \n",
       "1               1              0           0               1                1   \n",
       "2               1              1           1               0                1   \n",
       "3               1              1           0               1                1   \n",
       "4               0              0           0               0                1   \n",
       "\n",
       "   stock knowledge_ind  frequency _ind  history_ind  technical_ind  \n",
       "0                    0               0            0              0  \n",
       "1                    0               1            0              0  \n",
       "2                    0               1            1              0  \n",
       "3                    0               0            0              0  \n",
       "4                    0               1            1              0  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:/Users/hongz/Downloads/choices13k-main/reg_data_main2.csv\")\n",
    "# Modify graph_id as specified\n",
    "data['graph_id'] = data['graph_id'] + 100 * data['reshuffle_ind']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3a8a8095-0db5-4d61-ae71-4c84422ec6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>graph_id</th>\n",
       "      <th>time</th>\n",
       "      <th>click</th>\n",
       "      <th>risk</th>\n",
       "      <th>forecast</th>\n",
       "      <th>confidence</th>\n",
       "      <th>investment</th>\n",
       "      <th>reason_risky</th>\n",
       "      <th>reason_confidence</th>\n",
       "      <th>...</th>\n",
       "      <th>employment_ind</th>\n",
       "      <th>education_ind</th>\n",
       "      <th>income_ind</th>\n",
       "      <th>statistics_ind</th>\n",
       "      <th>risk-taking_ind</th>\n",
       "      <th>stock knowledge_ind</th>\n",
       "      <th>frequency _ind</th>\n",
       "      <th>history_ind</th>\n",
       "      <th>technical_ind</th>\n",
       "      <th>subject_id_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5fbb4426e47b46c3e2eeb544</td>\n",
       "      <td>156</td>\n",
       "      <td>11.55000000</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>112</td>\n",
       "      <td>62</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65981b2c1df3be0020afa351</td>\n",
       "      <td>154</td>\n",
       "      <td>57.60100000</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>95</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>The ones that had big dips in them.</td>\n",
       "      <td>A lot of them. Only because I'm slowly trying ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655791684bb1c5db02826d17</td>\n",
       "      <td>192</td>\n",
       "      <td>48.95800000</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>91</td>\n",
       "      <td>100</td>\n",
       "      <td>51</td>\n",
       "      <td>If it fluctuates more than 20% within 12 months.</td>\n",
       "      <td>With a $3 investment I do not feel unconfident...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62ddbd7eb3e9431e49b46ec1</td>\n",
       "      <td>182</td>\n",
       "      <td>49.95000000</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>115</td>\n",
       "      <td>79</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5fb13091b87dfd5888f73e05</td>\n",
       "      <td>180</td>\n",
       "      <td>45.07000000</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>93</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>Those that have big drops.</td>\n",
       "      <td>When they are inconsistent and up and down on ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 subject_id  graph_id        time  click  risk  forecast  \\\n",
       "0  5fbb4426e47b46c3e2eeb544       156 11.55000000      6     6       112   \n",
       "1  65981b2c1df3be0020afa351       154 57.60100000     10     8        95   \n",
       "2  655791684bb1c5db02826d17       192 48.95800000     16     7        91   \n",
       "3  62ddbd7eb3e9431e49b46ec1       182 49.95000000     11     8       115   \n",
       "4  5fb13091b87dfd5888f73e05       180 45.07000000      8     5        93   \n",
       "\n",
       "   confidence  investment                                      reason_risky  \\\n",
       "0          62          59                                               NaN   \n",
       "1          14           9               The ones that had big dips in them.   \n",
       "2         100          51  If it fluctuates more than 20% within 12 months.   \n",
       "3          79          60                                               NaN   \n",
       "4          20           0                        Those that have big drops.   \n",
       "\n",
       "                                   reason_confidence  ...  employment_ind  \\\n",
       "0                                                NaN  ...               0   \n",
       "1  A lot of them. Only because I'm slowly trying ...  ...               1   \n",
       "2  With a $3 investment I do not feel unconfident...  ...               1   \n",
       "3                                                NaN  ...               1   \n",
       "4  When they are inconsistent and up and down on ...  ...               0   \n",
       "\n",
       "   education_ind  income_ind  statistics_ind  risk-taking_ind  \\\n",
       "0              1           1               0                0   \n",
       "1              0           0               1                1   \n",
       "2              1           1               0                1   \n",
       "3              1           0               1                1   \n",
       "4              0           0               0                1   \n",
       "\n",
       "   stock knowledge_ind  frequency _ind  history_ind  technical_ind  \\\n",
       "0                    0               0            0              0   \n",
       "1                    0               1            0              0   \n",
       "2                    0               1            1              0   \n",
       "3                    0               0            0              0   \n",
       "4                    0               1            1              0   \n",
       "\n",
       "   subject_id_encoded  \n",
       "0                 185  \n",
       "1                 461  \n",
       "2                 438  \n",
       "3                 307  \n",
       "4                 183  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform 'subject_id' to numeric\n",
    "data['subject_id_encoded'] = le.fit_transform(data['subject_id'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f42c18c-503c-4fa1-a388-c471424e5654",
   "metadata": {},
   "source": [
    "Baseline Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3e244a17-d283-4b8f-8f99-49c1f6d5b112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006575680627034064"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define independent variables for the baseline regression\n",
    "X_base = data[['Obj_Std', 'Skewness', 'Kurtosis', 'time', 'click', 'order', 'subject_id_encoded']]\n",
    "\n",
    "# Split the data\n",
    "X_train_base, X_test_base, y_train, y_test = train_test_split(X_base, data['confidence'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Baseline regression\n",
    "model_base = LinearRegression()\n",
    "model_base.fit(X_train_base, y_train)\n",
    "y_pred_base = model_base.predict(X_test_base)\n",
    "r2_base = r2_score(y_test, y_pred_base)\n",
    "r2_base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdba029-d683-4eed-8898-085ed3ea87da",
   "metadata": {},
   "source": [
    "3 Feature Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c861fe50-b769-4342-b25e-3ebcc2e69cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006906556308739598"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_3_feature = data[['Obj_Std', 'Skewness', 'Kurtosis', 'time', 'click', 'order', 'subject_id_encoded', 'Recency_Factor', 'Rep_Factor', 'Sign_Factor']]\n",
    "X_train_3, X_test_3 = train_test_split(X_3_feature, test_size=0.2, random_state=42)\n",
    "\n",
    "model_3_feature = LinearRegression()\n",
    "model_3_feature.fit(X_train_3, y_train)\n",
    "y_pred_3 = model_3_feature.predict(X_test_3)\n",
    "r2_3_feature = r2_score(y_test, y_pred_3)\n",
    "r2_3_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd8a384-6e2b-41cc-a9b0-b7df52baa3b3",
   "metadata": {},
   "source": [
    "8 Feature Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "60ff051e-eb9e-423c-ab95-57503cad11d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005858440493053729"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_8_feature = data[['Obj_Std', 'Skewness', 'Kurtosis', 'time', 'click', 'order', 'subject_id_encoded', 'Recency_Factor', 'Rep_Factor', 'Sign_Factor', 'SH_Rep_Factor', 'SH_Sign_Factor', 'SH_Obj_Std', 'SH_Skewness', 'SH_Kurtosis']]\n",
    "X_train_8, X_test_8 = train_test_split(X_8_feature, test_size=0.2, random_state=42)\n",
    "\n",
    "model_8_feature = LinearRegression()\n",
    "model_8_feature.fit(X_train_8, y_train)\n",
    "y_pred_8 = model_8_feature.predict(X_test_8)\n",
    "r2_8_feature = r2_score(y_test, y_pred_8)\n",
    "r2_8_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9684500-4e83-45b3-adab-70c7485ba8a1",
   "metadata": {},
   "source": [
    "Graph FE Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "91ec4aaf-7216-4bba-a0da-34a0cd4be178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.005168410370678611"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming 'data' is your DataFrame and 'graph_id' is the categorical variable\n",
    "graph_id_dummies = pd.get_dummies(data['graph_id'], prefix='graph_id')\n",
    "data_with_fe = pd.concat([data, graph_id_dummies], axis=1)\n",
    "\n",
    "# Create a list of features including the dummy variables\n",
    "features = ['time', 'click', 'order', 'subject_id_encoded'] + list(graph_id_dummies.columns)\n",
    "\n",
    "# Select these features for X\n",
    "X_graph_id_fe = data_with_fe[features]\n",
    "\n",
    "# Assuming y_train and y_test are defined or create them if not mentioned\n",
    "X_train_graph_id_fe, X_test_graph_id_fe = train_test_split(X_graph_id_fe, test_size=0.2, random_state=42)\n",
    "#X_train_graph_id_fe, X_test_graph_id_fe, y_train, y_test = train_test_split(X_graph_id_fe, data['confidence'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the baseline regression model\n",
    "model_graph_id_fe = LinearRegression()\n",
    "model_graph_id_fe.fit(X_train_graph_id_fe, y_train)\n",
    "\n",
    "# Predict and calculate the R-squared value\n",
    "y_pred_graph_id_fe = model_graph_id_fe.predict(X_test_graph_id_fe)\n",
    "r2_graph_id_fe = r2_score(y_test, y_pred_graph_id_fe)\n",
    "\n",
    "r2_graph_id_fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0977b1ef-9b2c-4ed3-8331-fd470aaa4203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82b18cea-7724-4cab-832e-d8ef673269cb",
   "metadata": {},
   "source": [
    "## With Fixed Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1f119536-8ca2-4251-9fb5-bea32543fab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables for 'subject_id_encoded' and 'graph_id'\n",
    "subject_id_dummies = pd.get_dummies(data['subject_id_encoded'], prefix='subject_id')\n",
    "#graph_id_dummies = pd.get_dummies(data['graph_id'], prefix='graph_id')\n",
    "\n",
    "# Add these dummy variables to the data\n",
    "data_with_dummies = pd.concat([data, subject_id_dummies], axis=1)\n",
    "data_with_dummies = pd.concat([data_with_dummies, graph_id_dummies], axis=1)\n",
    "# Define the baseline features including the subject_id dummies\n",
    "baseline_features_with_dummies = ['Obj_Std', 'Skewness', 'Kurtosis', 'time', 'click', 'order'] + list(subject_id_dummies.columns)\n",
    "#baseline_features_with_dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6116b727-508d-4b09-a024-504ebaae3441",
   "metadata": {},
   "source": [
    "Baseline Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "defd065c-de67-4cd1-88a1-4b4c21062eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6457058745388641"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the independent and dependent variables\n",
    "X_baseline_with_dummies = data_with_dummies[baseline_features_with_dummies]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_baseline, X_test_baseline = train_test_split(X_baseline_with_dummies, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the baseline regression model\n",
    "model_baseline_with_dummies = LinearRegression()\n",
    "model_baseline_with_dummies.fit(X_train_baseline, y_train)\n",
    "\n",
    "# Predict and calculate the R-squared value\n",
    "y_pred_baseline = model_baseline_with_dummies.predict(X_test_baseline)\n",
    "r2_baseline_fe = r2_score(y_test, y_pred_baseline)\n",
    "\n",
    "r2_baseline_fe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cbd3d9-d359-43a2-93f6-ed16427f45cd",
   "metadata": {},
   "source": [
    "3 Feature Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "92a5bd6d-939e-4a74-b0b7-9f65da972267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6477475104690575"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define 3-feature model variables\n",
    "features_3_feature = baseline_features_with_dummies + ['Recency_Factor', 'Rep_Factor', 'Sign_Factor']\n",
    "\n",
    "# Split the data for 3-feature model\n",
    "X_3_feature = data_with_dummies[features_3_feature]\n",
    "X_train_3_feature, X_test_3_feature = train_test_split(X_3_feature, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the 3-feature model\n",
    "model_3_feature = LinearRegression()\n",
    "model_3_feature.fit(X_train_3_feature, y_train)\n",
    "\n",
    "# Predict and calculate R-squared\n",
    "y_pred_3_feature = model_3_feature.predict(X_test_3_feature)\n",
    "r2_3_feature_fe = r2_score(y_test, y_pred_3_feature)\n",
    "r2_3_feature_fe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477770b4-fd3a-4306-917e-8bc56efd0fec",
   "metadata": {},
   "source": [
    "8 Feature Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7ecc6dfa-1c2e-4a8f-89eb-9e5c71995a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6466063488226277"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define 8-feature model variables including 'subject_id_encoded' dummies\n",
    "features_8_feature = baseline_features_with_dummies + ['Recency_Factor', 'Rep_Factor', 'Sign_Factor', 'SH_Rep_Factor', 'SH_Sign_Factor', 'SH_Obj_Std', 'SH_Skewness', 'SH_Kurtosis']\n",
    "\n",
    "# Split the data for 8-feature model\n",
    "X_8_feature = data_with_dummies[features_8_feature]\n",
    "X_train_8_feature, X_test_8_feature = train_test_split(X_8_feature, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the 8-feature model\n",
    "model_8_feature = LinearRegression()\n",
    "model_8_feature.fit(X_train_8_feature, y_train)\n",
    "\n",
    "# Predict and calculate R-squared\n",
    "y_pred_8_feature = model_8_feature.predict(X_test_8_feature)\n",
    "r2_8_feature_fe = r2_score(y_test, y_pred_8_feature)\n",
    "r2_8_feature_fe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3000bfba-306e-4ca1-bdf1-6974786c9238",
   "metadata": {},
   "source": [
    "Graph FE Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1ac886c3-9878-4435-9a59-83509aee5d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6412374352475405"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming data_with_dummies already includes the necessary dummy variables\n",
    "graph_fe_features = ['Obj_Std', 'Skewness', 'Kurtosis', 'time', 'click', 'order'] + list(subject_id_dummies.columns) + list(graph_id_dummies.columns)\n",
    "X_graph_with_dummies = data_with_dummies[graph_fe_features]\n",
    "\n",
    "# Ensure that the order and columns used in the model are consistent\n",
    "X_train_graph_id, X_test_graph_id = train_test_split(X_graph_with_dummies,test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the baseline regression model with dummies\n",
    "model_graph_id_with_dummies = LinearRegression()\n",
    "model_graph_id_with_dummies.fit(X_train_graph_id, y_train)\n",
    "\n",
    "# Predict and calculate the R-squared value\n",
    "y_pred_graph_id = model_graph_id_with_dummies.predict(X_test_graph_id)\n",
    "r2_graph_fe = r2_score(y_test, y_pred_graph_id)\n",
    "r2_graph_fe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100d66d4-f0cb-4f16-b6ee-ab3247dbe18e",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "199dcc4d-9136-41a4-8c83-ae4f692cbf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify all 'ret_' and 'price_' columns\n",
    "ret_columns = [col for col in data.columns if col.startswith('ret_')]\n",
    "price_columns = [col for col in data.columns if col.startswith('price_')]\n",
    "\n",
    "# Identify all 'ret_', 'price_', and their differences columns\n",
    "ret_1st_diff_columns = [col for col in data.columns if '1st_diff' in col and col.startswith('ret_')]\n",
    "ret_2nd_diff_columns = [col for col in data.columns if '2nd_diff' in col and col.startswith('ret_')]\n",
    "price_1st_diff_columns = [col for col in data.columns if '1st_diff' in col and col.startswith('price_')]\n",
    "price_2nd_diff_columns = [col for col in data.columns if '2nd_diff' in col and col.startswith('price_')]\n",
    "\n",
    "# Combine these columns with your other features for the Huge Lasso model\n",
    "features_huge_lasso = ['Obj_Std', 'Skewness', 'Kurtosis', 'time', 'click', 'order', 'subject_id_encoded', 'Recency_Factor', 'Rep_Factor', 'Sign_Factor', 'SH_Rep_Factor', 'SH_Sign_Factor', 'SH_Obj_Std', 'SH_Skewness', 'SH_Kurtosis'] + ret_columns + price_columns + ret_1st_diff_columns + ret_2nd_diff_columns + price_1st_diff_columns + price_2nd_diff_columns\n",
    "X_huge_lasso = data[features_huge_lasso]\n",
    "X_train_huge, X_test_huge = train_test_split(X_huge_lasso, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "18b4b340-eb6f-4c84-a4ec-86eaccc52668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean R-squared for Lasso with 10-Fold CV: 0.0063 Â± 0.0055\n"
     ]
    }
   ],
   "source": [
    "def lasso_kfold_cv(data, features, target):\n",
    "    X = data[features]\n",
    "    y = data[target]\n",
    "    \n",
    "    # Standardizing the data\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Setting up 10-fold cross-validation\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Using LassoCV to find the best alpha during cross-validation\n",
    "    lasso_cv = LassoCV(alphas=np.logspace(-6, 0, 100), cv=kf, random_state=42)\n",
    "    lasso_cv.fit(X_scaled, y)\n",
    "\n",
    "    # Evaluating the model using cross-validation\n",
    "    cv_scores = cross_val_score(lasso_cv, X_scaled, y, cv=kf, scoring='r2')\n",
    "    mean_r2 = np.mean(cv_scores)\n",
    "    std_r2 = np.std(cv_scores)\n",
    "\n",
    "    return mean_r2, std_r2\n",
    "\n",
    "# Using the model\n",
    "features_base = ['Obj_Std', 'Skewness', 'Kurtosis', 'time', 'click', 'order', 'subject_id_encoded', 'Recency_Factor', 'Rep_Factor', 'Sign_Factor', 'SH_Rep_Factor', 'SH_Sign_Factor', 'SH_Obj_Std', 'SH_Skewness', 'SH_Kurtosis']\n",
    "r2_8_feature_lasso, std_8_feature_lasso = lasso_kfold_cv(data, features_base, 'confidence')\n",
    "print(f\"Mean R-squared for Lasso with 10-Fold CV: {r2_8_feature_lasso:.4f} Â± {std_8_feature_lasso:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1adf8dee-d374-482d-91b6-6eaa62c602c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean R-squared for Large Lasso with 10-Fold CV: 0.0058 Â± 0.0055\n",
      "Mean R-squared for Huge Lasso with 10-Fold CV: 0.0056 Â± 0.0053\n"
     ]
    }
   ],
   "source": [
    "# Extracting ret and price features\n",
    "ret_features = [col for col in data.columns if col.startswith('ret_') and 'diff' not in col]\n",
    "price_features = [col for col in data.columns if col.startswith('price_') and 'diff' not in col]\n",
    "\n",
    "# Large Lasso features include base features plus all ret_ and price_ values\n",
    "features_large = features_base + ret_features + price_features\n",
    "\n",
    "# Adding first and second differences for Huge Lasso features\n",
    "ret_diff_features = [col for col in data.columns if 'ret_' in col and 'diff' in col]\n",
    "price_diff_features = [col for col in data.columns if 'price_' in col and 'diff' in col]\n",
    "\n",
    "features_huge = features_large + ret_diff_features + price_diff_features\n",
    "\n",
    "# Calculate R-squared for Large Lasso\n",
    "r2_large_lasso, std_r2_large = lasso_kfold_cv(data, features_large, 'confidence')\n",
    "print(f\"Mean R-squared for Large Lasso with 10-Fold CV: {r2_large_lasso:.4f} Â± {std_r2_large:.4f}\")\n",
    "\n",
    "# Calculate R-squared for Huge Lasso\n",
    "r2_huge_lasso, std_r2_huge = lasso_kfold_cv(data, features_huge, 'confidence')\n",
    "print(f\"Mean R-squared for Huge Lasso with 10-Fold CV: {r2_huge_lasso:.4f} Â± {std_r2_huge:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9abdd6-72bd-4c31-a3ce-ae05f4ec6483",
   "metadata": {},
   "source": [
    "lasso within subjected_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5cf0b286-b7bc-44ad-a1ef-41cec6f83d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean R-squared for Lasso with 10-Fold CV: -0.0173 Â± 0.0165\n"
     ]
    }
   ],
   "source": [
    "from sklearn import set_config\n",
    "set_config(enable_metadata_routing=False)  # Explicitly disable metadata routing\n",
    "\n",
    "def lasso_group_kfold_cv(data, features, target):\n",
    "    X = data[features]\n",
    "    y = data[target]\n",
    "    groups = data['subject_id_encoded']  # This assumes subject_id_encoded is a column in the DataFrame\n",
    "\n",
    "    # Setting up 10-fold cross-validation that respects groups\n",
    "    gkf = GroupKFold(n_splits=10)\n",
    "\n",
    "    # Create a pipeline to scale data and apply Lasso\n",
    "    lasso_pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('lasso_cv', LassoCV(alphas=np.logspace(-6, 0, 100), max_iter=10000, random_state=42))\n",
    "    ])\n",
    "\n",
    "    # Compute cross-validated R^2 scores\n",
    "    cv_scores = cross_val_score(lasso_pipeline, X, y, groups=groups, cv=gkf, scoring='r2')\n",
    "    mean_r2 = np.mean(cv_scores)\n",
    "    std_r2 = np.std(cv_scores)\n",
    "\n",
    "    return mean_r2, std_r2\n",
    "\n",
    "# Usage example\n",
    "features_base = ['Obj_Std', 'Skewness', 'Kurtosis', 'time', 'click', 'order', 'subject_id_encoded', 'Recency_Factor', 'Rep_Factor', 'Sign_Factor', 'SH_Rep_Factor', 'SH_Sign_Factor', 'SH_Obj_Std', 'SH_Skewness', 'SH_Kurtosis']\n",
    "r2_8_feature_lasso, std_8_feature_lasso = lasso_group_kfold_cv(data, features_base, 'confidence')\n",
    "print(f\"Mean R-squared for Lasso with 10-Fold CV: {r2_8_feature_lasso:.4f} Â± {std_8_feature_lasso:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3116132f-7beb-4a16-93a9-1df03eaf602d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean R-squared for Large Lasso with 10-Fold CV: -0.0177 Â± 0.0152\n",
      "Mean R-squared for Huge Lasso with 10-Fold CV: -0.0177 Â± 0.0151\n"
     ]
    }
   ],
   "source": [
    "# Large Lasso\n",
    "r2_large_lasso, std_r2_large_lasso = lasso_group_kfold_cv(data, features_large, 'confidence')\n",
    "print(f\"Mean R-squared for Large Lasso with 10-Fold CV: {r2_large_lasso:.4f} Â± {std_r2_large_lasso:.4f}\")\n",
    "\n",
    "# Huge Lasso\n",
    "r2_huge_lasso, std_r2_huge_lasso = lasso_group_kfold_cv(data, features_huge, 'confidence')\n",
    "print(f\"Mean R-squared for Huge Lasso with 10-Fold CV: {r2_huge_lasso:.4f} Â± {std_r2_huge_lasso:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b2500b-37a4-43da-9578-3eea585302ff",
   "metadata": {},
   "source": [
    "With control of subject_id_encoded FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6f50c5e9-e420-4ad3-914f-c8476dd0324e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean R-squared for Lasso with 10-Fold CV: 0.0063 Â± 0.0055\n"
     ]
    }
   ],
   "source": [
    "r2_8_feature_lasso_fe, std_8_feature_lasso = lasso_kfold_cv(data_with_dummies, features_base, 'confidence')\n",
    "print(f\"Mean R-squared for Lasso with 10-Fold CV: {r2_8_feature_lasso_fe:.4f} Â± {std_8_feature_lasso:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "81cfd1cf-c6da-4c3e-9f2e-9343efd6aae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean R-squared for Large Lasso with 10-Fold CV: -0.0177 Â± 0.0152\n",
      "Mean R-squared for Huge Lasso with 10-Fold CV: -0.0177 Â± 0.0151\n"
     ]
    }
   ],
   "source": [
    "r2_large_lasso_fe, std_r2_large_lasso = lasso_group_kfold_cv(data_with_dummies, features_large, 'confidence')\n",
    "print(f\"Mean R-squared for Large Lasso with 10-Fold CV: {r2_large_lasso_fe:.4f} Â± {std_r2_large_lasso:.4f}\")\n",
    "\n",
    "# Huge Lasso\n",
    "r2_huge_lasso_fe, std_r2_huge_lasso = lasso_group_kfold_cv(data_with_dummies, features_huge, 'confidence')\n",
    "print(f\"Mean R-squared for Huge Lasso with 10-Fold CV: {r2_huge_lasso_fe:.4f} Â± {std_r2_huge_lasso:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c579e953-07b6-4141-b2bc-e4074913a7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model(Confidence)</th>\n",
       "      <th>R-squared (Without Subject ID FE)</th>\n",
       "      <th>R-squared (With Subject ID FE)</th>\n",
       "      <th>R-squared (Demeaned)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline Regression</td>\n",
       "      <td>0.00657568</td>\n",
       "      <td>0.64570587</td>\n",
       "      <td>0.01064144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3-feature Regression</td>\n",
       "      <td>0.00690656</td>\n",
       "      <td>0.64774751</td>\n",
       "      <td>0.01762215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8-feature Regression</td>\n",
       "      <td>0.00585844</td>\n",
       "      <td>0.64660635</td>\n",
       "      <td>0.01477908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8-feature Lasso</td>\n",
       "      <td>-0.01728875</td>\n",
       "      <td>0.00630441</td>\n",
       "      <td>0.01290238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Large Lasso</td>\n",
       "      <td>-0.01771068</td>\n",
       "      <td>-0.01771068</td>\n",
       "      <td>0.01285531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Huge Lasso</td>\n",
       "      <td>-0.01771068</td>\n",
       "      <td>-0.01771068</td>\n",
       "      <td>0.01285531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Graph FE Regression</td>\n",
       "      <td>-0.00516841</td>\n",
       "      <td>0.64123744</td>\n",
       "      <td>-325737150942288216064.00000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model(Confidence)  R-squared (Without Subject ID FE)  \\\n",
       "0   Baseline Regression                         0.00657568   \n",
       "1  3-feature Regression                         0.00690656   \n",
       "2  8-feature Regression                         0.00585844   \n",
       "3       8-feature Lasso                        -0.01728875   \n",
       "4           Large Lasso                        -0.01771068   \n",
       "5            Huge Lasso                        -0.01771068   \n",
       "6   Graph FE Regression                        -0.00516841   \n",
       "\n",
       "   R-squared (With Subject ID FE)            R-squared (Demeaned)  \n",
       "0                      0.64570587                      0.01064144  \n",
       "1                      0.64774751                      0.01762215  \n",
       "2                      0.64660635                      0.01477908  \n",
       "3                      0.00630441                      0.01290238  \n",
       "4                     -0.01771068                      0.01285531  \n",
       "5                     -0.01771068                      0.01285531  \n",
       "6                      0.64123744 -325737150942288216064.00000000  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the DataFrame\n",
    "dak = {\n",
    "    \"Model(Confidence)\": [\n",
    "        \"Baseline Regression\", \"3-feature Regression\", \"8-feature Regression\",\n",
    "        \"8-feature Lasso\", \"Large Lasso\", \"Huge Lasso\", \"Graph FE Regression\"\n",
    "    ],\n",
    "    \"R-squared (Without Subject ID FE)\": [\n",
    "        r2_base, r2_3_feature, r2_8_feature,\n",
    "        r2_8_feature_lasso, r2_large_lasso, r2_large_lasso, r2_graph_id_fe\n",
    "    ],\n",
    "    \"R-squared (With Subject ID FE)\": [\n",
    "        r2_baseline_fe, r2_3_feature_fe, r2_8_feature_fe,\n",
    "        r2_8_feature_lasso_fe, r2_large_lasso_fe, r2_large_lasso_fe, r2_graph_fe\n",
    "    ],\n",
    "    \"R-squared (Demeaned)\": [\n",
    "        r2_base_demeaned, r2_3_feature_demeaned, r2_8_feature_demeaned,\n",
    "        r2_8_feature_lasso_demeaned, r2_large_lasso_demeaned, r2_large_lasso_demeaned, r2_graph_id_fe_demeaned\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(dak)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700305fd-b154-40da-8446-a0395d20652f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eb07b568-37e1-44bd-a78e-ce04eac5566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Demean all variables except subject_id\n",
    "grouped = data.groupby('subject_id')\n",
    "data_demeaned = grouped.transform(lambda x: x - x.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6a609f53-486c-4a8e-8607-f89699bb5ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01064144361972097"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define independent variables for the baseline regression\n",
    "X_base = data_demeaned[['Obj_Std', 'Skewness', 'Kurtosis', 'time', 'click', 'order', 'subject_id_encoded']]\n",
    "y = data_demeaned['confidence']\n",
    "# Split the data\n",
    "X_train_base, X_test_base, y_train, y_test = train_test_split(X_base, data_demeaned['confidence'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Baseline regression\n",
    "model_base_demeaned = LinearRegression()\n",
    "model_base_demeaned.fit(X_train_base, y_train)\n",
    "y_pred_base_demeaned = model_base_demeaned.predict(X_test_base)\n",
    "r2_base_demeaned = r2_score(y_test, y_pred_base_demeaned)\n",
    "r2_base_demeaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5b19ea94-07b2-49d6-976b-3d5620c50546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017622149443554003"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_3_feature = data_demeaned[['Obj_Std', 'Skewness', 'Kurtosis', 'time', 'click', 'order', 'subject_id_encoded', 'Recency_Factor', 'Rep_Factor', 'Sign_Factor']]\n",
    "X_train_3, X_test_3 = train_test_split(X_3_feature, test_size=0.2, random_state=42)\n",
    "\n",
    "model_3_feature_demeaned = LinearRegression()\n",
    "model_3_feature_demeaned.fit(X_train_3, y_train)\n",
    "y_pred_3_demeaned = model_3_feature_demeaned.predict(X_test_3)\n",
    "r2_3_feature_demeaned = r2_score(y_test, y_pred_3_demeaned)\n",
    "r2_3_feature_demeaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1f9b4a24-a683-4539-acee-f2aa35db5944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014779082636650509"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_8_feature = data_demeaned[['Obj_Std', 'Skewness', 'Kurtosis', 'time', 'click', 'order', 'subject_id_encoded', 'Recency_Factor', 'Rep_Factor', 'Sign_Factor', 'SH_Rep_Factor', 'SH_Sign_Factor', 'SH_Obj_Std', 'SH_Skewness', 'SH_Kurtosis']]\n",
    "X_train_8, X_test_8 = train_test_split(X_8_feature, test_size=0.2, random_state=42)\n",
    "\n",
    "model_8_feature = LinearRegression()\n",
    "model_8_feature.fit(X_train_8, y_train)\n",
    "y_pred_8 = model_8_feature.predict(X_test_8)\n",
    "r2_8_feature_demeaned = r2_score(y_test, y_pred_8)\n",
    "r2_8_feature_demeaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b614f7ee-c007-4186-adaa-64b28ea6d0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean R-squared for Lasso with 10-Fold CV: 0.0129 Â± 0.0059\n"
     ]
    }
   ],
   "source": [
    "r2_8_feature_lasso_demeaned, std_8_feature_lasso_demeaned = lasso_kfold_cv(data_demeaned, features_base, 'confidence')\n",
    "print(f\"Mean R-squared for Lasso with 10-Fold CV: {r2_8_feature_lasso_demeaned:.4f} Â± {std_8_feature_lasso_demeaned:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "288061aa-7a1a-435d-9211-f7640a417a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean R-squared for Large Lasso with 10-Fold CV: 0.0129 Â± 0.0081\n",
      "Mean R-squared for Huge Lasso with 10-Fold CV: 0.0118 Â± 0.0079\n"
     ]
    }
   ],
   "source": [
    "# Calculate R-squared for Large Lasso\n",
    "r2_large_lasso_demeaned, std_r2_large_demeaned = lasso_kfold_cv(data_demeaned, features_large, 'confidence')\n",
    "print(f\"Mean R-squared for Large Lasso with 10-Fold CV: {r2_large_lasso_demeaned:.4f} Â± {std_r2_large_demeaned:.4f}\")\n",
    "\n",
    "# Calculate R-squared for Huge Lasso\n",
    "r2_huge_lasso_demeaned, std_r2_huge_demeaned = lasso_kfold_cv(data_demeaned, features_huge, 'confidence')\n",
    "print(f\"Mean R-squared for Huge Lasso with 10-Fold CV: {r2_huge_lasso_demeaned:.4f} Â± {std_r2_huge_demeaned:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8147cf30-b0f1-470e-84e4-5fbfeb5b6130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.257371509422882e+20"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming 'data' is your DataFrame and 'graph_id' is the categorical variable\n",
    "graph_id_dummies = pd.get_dummies(data_demeaned['graph_id'], prefix='graph_id')\n",
    "data_with_fe = pd.concat([data_demeaned, graph_id_dummies], axis=1)\n",
    "\n",
    "# Create a list of features including the dummy variables\n",
    "features = ['time', 'click', 'order', 'subject_id_encoded'] + list(graph_id_dummies.columns)\n",
    "\n",
    "# Select these features for X\n",
    "X_graph_id_fe = data_with_fe[features]\n",
    "\n",
    "# Assuming y_train and y_test are defined or create them if not mentioned\n",
    "X_train_graph_id_fe, X_test_graph_id_fe = train_test_split(X_graph_id_fe, test_size=0.2, random_state=42)\n",
    "#X_train_graph_id_fe, X_test_graph_id_fe, y_train, y_test = train_test_split(X_graph_id_fe, data['confidence'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the baseline regression model\n",
    "model_graph_id_fe = LinearRegression()\n",
    "model_graph_id_fe.fit(X_train_graph_id_fe, y_train)\n",
    "\n",
    "# Predict and calculate the R-squared value\n",
    "y_pred_graph_id_fe = model_graph_id_fe.predict(X_test_graph_id_fe)\n",
    "r2_graph_id_fe_demeaned = r2_score(y_test, y_pred_graph_id_fe)\n",
    "\n",
    "r2_graph_id_fe_demeaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43ef631-ea8a-4b90-ac8e-7bc4c870edc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
